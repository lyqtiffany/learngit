```python
#201018_网络爬虫
#requests模块,这个模块可以爬取网页内容
import re
import requests
import xlwt,xlrd
url='https://www.xs4.cc/0_4/'  #需要进行爬虫的网址
url2=re.findall('https://www.xs4.cc/(.*?)/',url)[0]  #提取书名所在网址的最后一段,后面要用
req=requests.get(url)  #实例化一个requests请求,提取网页内容
req.encoding='gbk'  #将编码转换为gbk,解决乱码问题
book_name=re.findall('<h1>(.*?)</h1>',req.text)[0]  #获取书名
mulu=re.findall('.html">(.*?)</a></dd>',req.text,re.S)
# for i in range(9,len(mulu)):
#     print(mulu[i])
wangzhi=re.findall(f'<a href="/{url2}/(.*?).html">',req.text,re.S)
dict1={}
for i in range(9,len(mulu)):
    dict1[mulu[i]]=f'{url}{wangzhi[i]}.html'  #将目录和网址存放到字典中
# for i in range(9,len(wangzhi)):
#     print(f'{url}{wangzhi[i]}.html')

# for k,v in dict1.items():
#     print(k,v)

excel1=xlwt.Workbook()  #实例化一个excel
worksheet=excel1.add_sheet(f'{book_name}')  #新建一个sheet
worksheet.write(0,0,'目录')  #行,列,内容
worksheet.write(0,1,'网址')
row=1
for k,v in dict1.items():
    worksheet.write(row,0,k)  #写入目录
    worksheet.write(row,1,v)  #写入网址
    row+=1
excel1.save(f'd:/{book_name}.xls')  #保存excel文件
#读取excel文件
data=xlrd.open_workbook(f'd:/{book_name}.xls')
sheet1=data.sheets()[0]  #读取文件的第一个sheet
# print(sheet1.nrows)  #nrows返回 excel中的有效行数
for i in range(1,sheet1.nrows):
    print(sheet1.cell_value(i,0),sheet1.cell_value(i,1))  #获取单元格内容

#上节课思考题,求某数的阶乘
def jiecheng(n):
    if n==1:
        return n
    else:
        return n*jiecheng(n-1)

#课后思考题,提取全书网正文
```